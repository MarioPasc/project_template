
# **Explorando la Demencia Frontotemporal mediante BiologÃ­a de Sistemas**

Este repositorio contiene el cÃ³digo y recursos asociados al anÃ¡lisis presentado en el estudio:  
**"Explorando la Demencia Frontotemporal mediante BiologÃ­a de Sistemas: Un Enfoque Integrado"**  

Autores:

- Mario Pascual GonzÃ¡lez
- Ainhoa Nerea Santana Bastante
- Carmen RodrÃ­guez GonzÃ¡lez
- Gonzalo Mesas Aranda
- Ainhoa PÃ©rez GonzÃ¡lez.  

---

## **ConfiguraciÃ³n del Entorno**

Las pruebas fueron realizadas en:  

- **Sistema Operativo:** Ubuntu 22.04.5 LTS
- **Kernel:** Linux 6.8.0-49-generic  
- **Procesador:** 13th Gen Intel i7-13700KF (24) @ 5.300GHz  
- **GPU:** NVIDIA GeForce RTX 3060  
- **Arquitectura:** x86_64  

### EjecuciÃ³n Completa del Pipeline

- Primera ejecuciÃ³n: 2024-11-22 11:40:01 
- Ãšltima EjecuciÃ³n: 2024-12-09 16:21:53  

---

## **InstalaciÃ³n y EjecuciÃ³n del Pipeline**

### **Forma Principal: EjecuciÃ³n Usando Docker Hub**

La forma mÃ¡s sencilla y recomendada es ejecutar el pipeline utilizando la [imagen preconstruida de Docker en Docker Hub](https://hub.docker.com/r/mpascualg/biosist_ftd). El script `launch.sh` se encargarÃ¡ de descargar y ejecutar la imagen.

1. **Clonado del Repositorio**  
   Clonar el repositorio usando `git`:

   ```bash
   git clone https://github.com/MarioPasc/project_template
   cd project_template
   ```

2. **EjecuciÃ³n del Pipeline**  
   Lanzar el pipeline completo ejecutando:

   ```bash
   ./code/launch.sh
   ```

   Este script:
   - Descarga la imagen preconstruida desde **Docker Hub**: `mariopasc/biosist_ftd:latest`.
   - Ejecuta el pipeline dentro de un contenedor Docker.
   - Monta las carpetas locales `results/` y `code/data/` para almacenar los resultados.

---

### **Formas Alternativas**

Si se prefiere no usar la imagen preconstruida de Docker Hub, puedes optar por las siguientes alternativas:

#### **1. Construir la Imagen Docker Localmente**

Si quieres construir la imagen tÃº mismo a partir del **Dockerfile**, sigue estos pasos:

1. **Construir la Imagen**  
   Ejecutar el siguiente comando en la raÃ­z del proyecto:

   ```bash
   docker build -t biosist_ftd:latest .
   ```

2. **EjecuciÃ³n del Pipeline con la Imagen Local**  
   Utilizar el script `launch.sh`, que ahora ejecutarÃ¡ la imagen localmente construida:

   ```bash
   ./code/launch.sh
   ```

---

#### **2. EjecuciÃ³n Manual sin Docker (No recomendado)**

Si no se puede usar Docker, tambiÃ©n se pueden instalar las dependencias y ejecutar el pipeline directamente en su mÃ¡quina local:

1. **InstalaciÃ³n de Dependencias**  
   Ejecutar el script `setup.sh` para instalar todas las dependencias de Python localmente:

   ```bash
   ./code/setup.sh
   ```

2. **EjecuciÃ³n del Pipeline**  
   Lanzar el pipeline ejecutando `execute.sh`:

   ```bash
   ./code/execute.sh
   ```

> [!CAUTION]
> Es muy probable que la generaciÃ³n del PDF no funcione con esta vÃ­a de ejecuciÃ³n, ya que esa parte del flujo ha sido programada ad hoc para Docker

---


| **Forma**                           | **Comando**                          | **Requisitos**                       |
|-------------------------------------|--------------------------------------|--------------------------------------|
| **Principal (Docker Hub)**          | `./code/launch.sh`                   | Docker instalado                     |
| **Alternativa 1 (Docker Local)**    | `docker build -t biosist_ftd .`<br>`./code/launch.sh` | Docker instalado                     |
| **Alternativa 2 (EjecuciÃ³n Local)** | `./code/setup.sh`<br>`./code/execute.sh` | Python instalado (>=3.10), Latex local (figuras), sin Docker |

### **Flujo de Trabajo Interno**  

1. **`launch.sh`**: Ejecuta Docker y monta las carpetas necesarias.  
2. **`execute.sh` (dentro del contenedor)**: Se encarga de ejecutar el pipeline completo, incluyendo:  
   - Descarga de datos de HPO.  
   - ConstrucciÃ³n y anÃ¡lisis de la red PPI.  
   - OptimizaciÃ³n bayesiana (si se habilita).  
   - GeneraciÃ³n de resultados y figuras.  

---

## **ParÃ¡metros de EjecuciÃ³n**

En el script **`execute.sh`**, se encuentran las siguientes variables:

| **Variable**  | **Valor por Defecto** | **DescripciÃ³n**                                                                                                                                                          |
|---------------|-----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **OPTIMIZE**  | `true`               | Controla si se realiza la optimizaciÃ³n bayesiana de hiperparÃ¡metros. Si estÃ¡ en `true`, se retomarÃ¡ desde el Ãºltimo intento si existen archivos `.db` en `results/`.     |
| **TRIALS**    | `100`                 | Define el nÃºmero de intentos del algoritmo de optimizaciÃ³n bayesiana. Se recomienda **80-100 iteraciones** para replicar los resultados del estudio original.           |

> [!CAUTION]
> Si se quiere modificar cualquiera de estas variables, se deben especificar en la llamada a `launch.sh`, ya que Docker se encargarÃ¡ de pasarlas a `execute.sh`:
> ```bash
> OPTIMIZE=true TRIALS=100 ./code/launch.sh
> ```

> [!CAUTION]
> Si se fija `OPTIMIZE=false`, entonces se debe renombrar la carpeta `original_results` a `results`, para que tome los resultados guardados ahÃ­. Esto se puede hacer fÃ¡cilmente con:
> ```bash
> mv ./original_results ./results
> ```

> [!IMPORTANT]
> Si `results/` estÃ¡ vacÃ­o y `OPTIMIZE=true`, el ajuste se iniciarÃ¡ desde cero. Si los archivos `.db` existen, se reanudarÃ¡ el ajuste.

> [!NOTE]
> Se estima 1 minuto por intento para cada algoritmo de clustering (Leiden y Louvain). Este tiempo puede estar relacionado con la configuraciÃ³n de hardware, pero sobre todo depende del estado de la API.

---

## **Estructura del Proyecto**

La estructura del proyecto estÃ¡ organizada de la siguiente manera:

```yaml
ðŸ“‚ project_template/
    â”œâ”€â”€ ðŸ“‚ code/                                              # CÃ³digo fuente principal
    â”‚   â”œâ”€â”€ ðŸ“‚ clustering/                                    # Scripts de clustering
    â”‚   â”œâ”€â”€ ðŸ“‚ functional_analysis/                           # Scripts de anÃ¡lisis funcional
    â”‚   â”œâ”€â”€ ðŸ“‚ network/                                       # Scripts de construcciÃ³n y anÃ¡lisis de redes
    â”‚   â”œâ”€â”€ ðŸ“‚ utils/                                         # Utilidades y funciones auxiliares
    â”‚   â”œâ”€â”€ setup.sh*                                         # Script para instalaciÃ³n de dependencias
    â”‚   â”œâ”€â”€ launch.sh*                                        # EjecuciÃ³n de la imagen Docker
    â”‚   â””â”€â”€ execute.sh*                                       # Script principal para ejecutar el pipeline
    â”‚
    â”œâ”€â”€ ðŸ“‚ report/                                            # DocumentaciÃ³n y reportes del estudio
    â”‚   â”œâ”€â”€ ...                   
    â”‚   â””â”€â”€ report.pdf                                        # ArtÃ­culo original del proyecto
    â”‚
    â”œâ”€â”€ ðŸ“‚ results/                                           # Resultados de las ejecuciones
    â”‚      â”œâ”€â”€ clustering_results.json                        # Resultados de clustering
    â”‚      â”œâ”€â”€ functional_analysis_leiden_max_enrichment.csv  # Resultados de enriquecimiento funcional sin filtrar
    â”‚      â”œâ”€â”€ functional_analysis_leiden_max_modularity.csv  # Resultados de enriquecimiento funcional sin filtrar
    â”‚      â”œâ”€â”€ filtered_results_leiden_max_enrichment.csv     # Resultados de enriquecimiento funcional filtrados
    â”‚      â”œâ”€â”€ filtered_results_leiden_max_modularity.csv     # Resultados de enriquecimiento funcional filtrados
    â”‚      â”œâ”€â”€ leiden_optimization.db                         # Resultados de optimizaciÃ³n Leiden
    â”‚      â”œâ”€â”€ multilevel_optimization.db                     # Resultados de optimizaciÃ³n Louvain
    â”‚      â”œâ”€â”€ networkAnalysisMetrics.tex                     # MÃ©tricas de anÃ¡lisis de la red
    â”‚      â”œâ”€â”€ results_leiden.csv                             # Resultados de optimizaciÃ³n Leiden (formato csv)
    â”‚      â”œâ”€â”€ results_multilevel.csv                         # Resultados de optimizaciÃ³n Louvain (formato csv)
    â”‚      â””â”€â”€ ðŸ“‚ plots/                                      # GrÃ¡ficos generados
    â”‚              â”œâ”€â”€ ðŸ“‚ clustering/                         # VisualizaciÃ³n de clustering
    â”‚              â”œâ”€â”€ ðŸ“‚ functional_analysis/                # GrÃ¡ficos de anÃ¡lisis funcional
    â”‚              â”œâ”€â”€ ðŸ“‚ network/                            # GrÃ¡ficos de redes
    â”‚              â””â”€â”€ ðŸ“‚ optimization/                       # GrÃ¡ficos de optimizaciÃ³n
    â”‚
    â”œâ”€â”€ Dockerfile                                            # Dockerfile con la configuraciÃ³n del entorno Docker
    â””â”€â”€ README.md                                             # DocumentaciÃ³n principal del proyecto
```

---

## **Resultados**

Los resultados incluyen:  

1. **Clustering Funcional:** Generado con algoritmos **Leiden** y **Louvain**.  
2. **AnÃ¡lisis Funcional:** Rutas biolÃ³gicas enriquecidas, incluyendo archivos `filtered_results` optimizados.  
3. **OptimizaciÃ³n Bayesiana:** Bases de datos `.db` con resultados de hiperparÃ¡metros ajustados.  
4. **VisualizaciÃ³n:** GrÃ¡ficos detallados en la carpeta `results/plots/`.

## **Contacto**

Se deja como contacto al alumno coordinador del proyecto, Mario Pascual GonzÃ¡lez:  
ðŸ“§ [pascualgonzalez.mario@uma.es](mailto:pascualgonzalez.mario@uma.es)